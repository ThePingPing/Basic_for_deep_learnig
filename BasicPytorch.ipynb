{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPRnPoKK8wn9SSO3RFRyfoN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ThePingPing/Basic_for_deep_learnig/blob/main/BasicPytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8X6TmyDyv2_e"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "h-eKIZ_IE2IA"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Introduction to Torch\n",
        "\n",
        "def introduction_to_torch():\n",
        "\n",
        "  scalar = torch.tensor(7)\n",
        "  print(scalar)\n",
        "\n",
        "  \"\"\" Check the dimention on a tensor \"\"\"\n",
        "\n",
        "  scalar_dim = scalar.ndim\n",
        "  print(scalar_dim) ## a scalar don't have dimention so == 0\n",
        "\n",
        "  \"\"\" Check what's is exactly this scalar with item() \"\"\"\n",
        "  scalar_item = scalar.item()\n",
        "  print(scalar_item)\n",
        "\n",
        "  ## create a vector\n",
        "\n",
        "  vec_tensor = torch.tensor([7, 7])\n",
        "  vec_dim = vec_tensor.ndim\n",
        "  print(vec_tensor)\n",
        "  print(vec_dim) ## the dimention is define by the number of square backets so == 1\n",
        "\n",
        "  vec_shape = vec_tensor.shape ## the difference between (Shape , dim) --> shape return the total numer of element\n",
        "\n",
        "  print(vec_shape)\n",
        "\n",
        "  \"\"\" Oki let's create a Matrix \"\"\"\n",
        "\n",
        "  mat = torch.tensor([[7, 7] , [1, 2]])\n",
        "  print(\"The matrix is: \" , mat)\n",
        "\n",
        "  \"\"\" To Get the First Row \"\"\" ## --> you have to give in the first composente the Row number\n",
        "\n",
        "  first_row = mat[0]\n",
        "  print(\"The first row is :\" , first_row)\n",
        "\n",
        "  first_element = mat[0][0]\n",
        "\n",
        "  print(\"First element is : \", first_element)\n",
        "\n",
        "  mat_shape = mat.shape\n",
        "  print(\"The shape of the Matrix is :\" , mat_shape)\n",
        "\n",
        "  \"\"\" Now Create a tensor == Multi Dim Vector \"\"\"\n",
        "\n",
        "  my_list = [i for i in range(3)]\n",
        "  print(my_list)\n",
        "\n",
        "  tensor = torch.tensor([[[i for i in range(3)],\n",
        "                        [i for i in range(3, 6)],\n",
        "                        [i for i in range(6, 9)]]])\n",
        "\n",
        "  print(\"my tensor is :\" , tensor)\n",
        "  tensor_shape = tensor.shape\n",
        "  print(\"The Shape is :\" , tensor_shape)\n"
      ],
      "metadata": {
        "id": "uE687DBLwFJZ"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "introduction_to_torch()"
      ],
      "metadata": {
        "id": "25RlPsAA0_5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def random_tensor():\n",
        "\n",
        "  ## Create a random tensors\n",
        "\n",
        "  random_tensor = torch.rand(size=(3, 4))\n",
        "  print(\" my random Tensors is : \", random_tensor) ## given the size is generate a tensort with all the numbers btween (0, 1)\n",
        "\n",
        "  \"\"\" Coz the tensors is good to define a image size create a tensors with similaire shape like a image \"\"\"\n",
        "\n",
        "  random_image_tensor_size = torch.rand(size=(3, 224, 224)) ## (width, height , chanels= (R, G , B) )\n",
        "\n",
        "  print(\"the Image Shape is :\" , random_image_tensor_size.shape)\n",
        "  print(\"the Image Dim is :\" , random_image_tensor_size.ndim)\n",
        "\n",
        "  ### Oki but you can also create a tensor with all zeros , or only ones\n",
        "\n",
        "  tensors_zeros = torch.zeros(size=(3, 3))\n",
        "  tensors_ones =  torch.ones(size=(3, 3))\n",
        "\n",
        "  print(\"Torch Zeros = :\" , tensors_zeros)\n",
        "  print(\"Torch Ones = :\" , tensors_ones)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "u2hVwyzb7k32"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_tensor()"
      ],
      "metadata": {
        "id": "LnXS1ez8815R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def arange_tensor():\n",
        "\n",
        "  ## you can directly use torch arange to create a serie of numbers in a tensor (so don't need numpy or a list, loop)\n",
        "\n",
        "  tensor_arange = torch.arange(0, 10).float() ## new vertion of torch use arrange, and don't forget the model in the futur work in floating point\n",
        "\n",
        "  print(\"my torch serie is : \", tensor_arange)\n",
        "\n",
        "  ## to create a tensor with the same size like a previouse one , we use _like\n",
        "\n",
        "  tensor_zeroes_like_arange = torch.zeros_like(input=(tensor_arange)) ## given the input\n",
        "\n",
        "  print(\"the zeros tensor like the Arange is :\" , tensor_zeroes_like_arange)\n"
      ],
      "metadata": {
        "id": "2Qc5WsW1_Ika"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arange_tensor()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXb8vaAiBZGF",
        "outputId": "4eec3636-fe53-45fd-b099-61b0fe2fdcb1"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "my torch serie is :  tensor([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
            "the zeros tensor like the Arange is : tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def data_type_tensor():\n",
        "\n",
        "  ## it's really important to work with float 32 in torch (model , optime , loss function)\n",
        "  ## we can change the type of element on useing dtype --> data Type\n",
        "\n",
        "  float_32_tensor = torch.tensor([3, 6, 9], dtype= torch.float32, device = None, requires_grad= False) ## device is to get the GPU or The CPU\n",
        "  print(\"The tensor 32 is:\" , float_32_tensor, \"the data Type is :\" , float_32_tensor.dtype)\n",
        "\n",
        "  \"\"\" We can change the type directly with .type \"\"\"\n",
        "\n",
        "  float_16_tensor = float_32_tensor.type(torch.half)\n",
        "  print(\"The tensor 16 is:\" , float_16_tensor, \"the data Type is :\" , float_16_tensor.dtype)"
      ],
      "metadata": {
        "id": "1r36f3mJDQ9b"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_type_tensor()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjGSZCtQEYH3",
        "outputId": "458c5f40-5da3-4660-8578-2956f6020454"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The tensor 32 is: tensor([3., 6., 9.]) the data Type is : torch.float32\n",
            "The tensor 16 is: tensor([3., 6., 9.], dtype=torch.float16) the data Type is : torch.float16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_attributes_tensor():\n",
        "\n",
        "  ## tensor attibutes --> shape, dtype, device\n",
        "  ## tensor function size()\n",
        "  random_tensor = torch.rand(3, 4)\n",
        "  print(random_tensor)\n",
        "  print(f\" The Datatype is {random_tensor.dtype} \")\n",
        "  print(f\"The shape of the tensor is {random_tensor.shape}\")\n",
        "  print(f\"The device is {random_tensor.device} \")\n"
      ],
      "metadata": {
        "id": "9Aizlqh-Eihr"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_attributes_tensor()"
      ],
      "metadata": {
        "id": "Qkrk59F_JzAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def manipulation_tensor():\n",
        "\n",
        "  ## tensor manipulation and operation --> (add, sub , mult, div , matrix multiplication)\n",
        "\n",
        "  basic_tensor = torch.tensor([1, 2, 3])\n",
        "  print(\"the basic tensor is :\", basic_tensor)\n",
        "  add_tensor = basic_tensor + 10\n",
        "  print(\"after add 10 to each element \", add_tensor)\n",
        "\n",
        "  mul_tensor = basic_tensor * 10\n",
        "  print(\"after multiply by 10 to each element \", mul_tensor)\n",
        "\n",
        "  \"\"\" But we can use the torch function \"\"\"\n",
        "\n",
        "  fuc_mul_tensor = torch.mul(basic_tensor, 10) ## given the Data and the mul factor, we have the same with torch.add(), torch.div()...\n",
        "\n",
        "  print(\"using Fuction multiply :\", fuc_mul_tensor)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1rR1WC2YLhXY"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "manipulation_tensor()"
      ],
      "metadata": {
        "id": "WIkf8WrvMsbP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def manipulation_matrix_tensor():\n",
        "\n",
        "  \"\"\" it's Extremely important to know how to multiply tow matrix for Deep Learning \"\"\"\n",
        "\n",
        "  basic_tensor = torch.tensor([1, 2, 3])\n",
        "\n",
        "  mult_tensor = basic_tensor * basic_tensor\n",
        "  scalar_fuc = torch.matmul( basic_tensor, basic_tensor) ## using matmul(A, B)\n",
        "  scalar_t = basic_tensor @ basic_tensor ## or use @\n",
        "\n",
        "\n",
        "  print(f\"The basic multiplication make a multiplication one to one: {mult_tensor}\")\n",
        "  print(f\"The scalar result by multiplication tow vectors: {scalar_fuc}\")\n",
        "  print(f\"The scalar result by multiplication tow vectors trnaspose: {scalar_t}\")\n"
      ],
      "metadata": {
        "id": "a4FK33iIOGUD"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "manipulation_matrix_tensor()"
      ],
      "metadata": {
        "id": "s1uCXSEvPs3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def statistics_value_tensor():\n",
        "\n",
        "   ## we ahe functions in torch to get the (Min, Max , Mean, STD)...\n",
        "   random_tensor = torch.rand(3, 4)\n",
        "   min_value = torch.min(random_tensor)\n",
        "   max_value = torch.max(random_tensor)\n",
        "   mean_value = torch.mean(random_tensor)\n",
        "   std_value = torch.std(random_tensor)\n",
        "   sum_value = torch.sum(random_tensor)\n",
        "   lenght_tensor = len(random_tensor)\n",
        "   print(\"the len is \", lenght_tensor)\n",
        "\n",
        "   print(f\"The random tensor is: {random_tensor}\")\n",
        "   print(f\"The Min Value is: {min_value}\")\n",
        "   print(f\"The Max Value is: {max_value}\")\n",
        "   print(f\"The Average / Mean is: {mean_value}\")\n",
        "   print(f\"The Standart deviation is: {std_value}\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UzqBLs4SVq__"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "statistics_value_tensor()"
      ],
      "metadata": {
        "id": "pVuSd-ofVyNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reshpe_tensor():\n",
        "\n",
        "  ## finding the position of the min and max value --> the index\n",
        "  random_tensor = torch.rand(3, 4)\n",
        "\n",
        "  \"\"\" argmax \"\"\"\n",
        "  max_value_index = torch.argmax(random_tensor[:][:]) ## in all the tensor using slicing\n",
        "  max_test = random_tensor.argmax() ## take directly using x.argmax()\n",
        "  min_value_index = torch.argmin(random_tensor)\n",
        "\n",
        "  print(f\"the Tensor is: {random_tensor}\")\n",
        "\n",
        "  print(f\"the index for the max value is: {max_value_index}\")\n",
        "  print(max_test)\n",
        "  print(f\"the index for the mmin value is: {min_value_index}\")\n",
        "\n",
        "\n",
        "  \"\"\" Reshape Operation \"\"\"\n",
        "\n",
        "  x = torch.arange(1., 11.)\n",
        "\n",
        "  x_reshape = x.reshape((1, 10)) ## the dimention have to mutch we the numbers of elementwith the original tensor\n",
        "  x_reshape_next = x.reshape((2, 5))\n",
        "\n",
        "  print(f\"The original Data {x}\")\n",
        "  print(f\"The first x_reshape is : {x_reshape} , the seconde is: {x_reshape_next}\")\n",
        "\n",
        "  \"\"\" With View \"\"\"\n",
        "\n",
        "  # z = x.view(1, 9) ## this operation dont change the memory so (x and z) are in dependency\n",
        "\n",
        "  \"\"\" stack, V-stack, H-stack \"\"\"\n",
        "  X_stack = torch.stack([x, x, x, x], dim=0) ## dim = 0 --> stacking vericaly , and dim = 1 horizontaly\n",
        "\n",
        "  print(f\"The X stack is: {X_stack}\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "o8aGfwufZE3A"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reshpe_tensor()"
      ],
      "metadata": {
        "id": "reWiJaI3Zu6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def squeezing_unsqueezing_tensor():\n",
        "\n",
        "  ## torch.squeeze() --> remove all the dimention on a tensor where dim = 1\n",
        "  ## torch.unsqueeze() --> add a single dimention on a tensor (dim = 0 rows, dim = 1--> col)\n",
        "\n",
        "  \"\"\" Start with Squeeze \"\"\"\n",
        "  x = torch.arange(1., 11.)\n",
        "  x_reshape = x.reshape((1, 10))\n",
        "  print(x.shape, f\"and the reshape is {x_reshape}, and the shape {x_reshape.shape}\")\n",
        "\n",
        "\n",
        "  x_squeeze_first = torch.squeeze(x_reshape)\n",
        "  x_squeeze_next = x_reshape.squeeze()\n",
        "\n",
        "  print(f\" We remove all the one dimention {x_squeeze_first.shape}\")\n",
        "  print(f\" We remove all the one dimention {x_squeeze_next.shape}\")\n",
        "  print(x_reshape.shape)\n",
        "\n",
        "  \"\"\" Now Unsqueeze \"\"\"\n",
        "\n",
        "  x_unsqueeze = x_squeeze_next.unsqueeze(dim = 0)\n",
        "  print(f\"The original shape is : {x_reshape.shape}\")\n",
        "  print(f\"after the squeeze shape is : {x_squeeze_next.shape}\")\n",
        "  print(f\"Back to the original shape : {x_unsqueeze.shape}\")\n",
        "\n",
        "  \"\"\" Permutation \"\"\"\n",
        "\n",
        "  ## torch.permute() --> permutation the orders in a tensors\n",
        "  x_image_size = torch.rand(size = (224, 224, 3))\n",
        "  x_permute = x_image_size.permute((2, 1, 0))\n",
        "  print(f\"the Original shape is : {x_image_size.shape}\")\n",
        "  print(f\"the Permutation is shape is : {x_permute.shape}\")\n"
      ],
      "metadata": {
        "id": "WOpDA7KZhc69"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "squeezing_unsqueezing_tensor()"
      ],
      "metadata": {
        "id": "PZFfV0UhiWwc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def indexing_slicing_tensor():\n",
        "\n",
        "  ## indexing and slicing work like in Numpy\n",
        "  x = torch.arange(1, 10).reshape(1, 3, 3)\n",
        "  print(f\" the first dimention on our tensor is: {x[0]}\")\n",
        "  print(f\" the first row in our tensor is: {x[0][0]}, and it's equal to {x[0, 0]}\")\n",
        "\n",
        "  x_second_col = x[:, :, 1] ## taking only the second columns\n",
        "\n",
        "  print(f\" The original tensor is: {x}, and the second columes is {x_second_col} \")\n"
      ],
      "metadata": {
        "id": "_FuxoLdOp7cF"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indexing_slicing_tensor()"
      ],
      "metadata": {
        "id": "TAVkm3ubqdPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def numpy_to_tensor():\n",
        "\n",
        "  ## work with Numpy and Torch\n",
        "  np_array = np.arange(1.0, 8.0)\n",
        "  tensor = torch.from_numpy(np_array)\n",
        "\n",
        "  print(f\"The numpy array is :{np_array}, and the tensor is: {tensor}\")\n",
        "\n",
        "  \"\"\" Random Seed \"\"\"\n",
        "  ## given one time a random numbers but, only one time , he gonna generate the same numbers\n",
        "  random_tensor_A = torch.rand(3, 4)\n",
        "  random_tensor_B = torch.rand(3, 4)\n",
        "\n",
        "  ## define the random seed\n",
        "\n",
        "  RANDOM_SEED = 42\n",
        "  random_tensor_seed = torch.manual_seed(RANDOM_SEED)\n",
        "  ## create the tensor\n",
        "  random_tensor_C = torch.rand(3, 4)\n",
        "\n",
        "  random_tensor_seed = torch.manual_seed(RANDOM_SEED)\n",
        "  random_tensor_D = torch.rand(3, 4)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  print(f\" the A tensor value is: {random_tensor_A}\")\n",
        "  print(f\" the B tensor value is: {random_tensor_B}\")\n",
        "  print(f\" the C tensor value is: {random_tensor_C}\")\n",
        "  print(f\" the D tensor value is: {random_tensor_D}\")\n",
        "  print(random_tensor_C == random_tensor_D)\n",
        "\n"
      ],
      "metadata": {
        "id": "BxfaNst4v0ag"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numpy_to_tensor()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1Az0mENwgjH",
        "outputId": "4506f5ce-f6f9-477a-c18f-42665570071b"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The numpy array is :[1. 2. 3. 4. 5. 6. 7.], and the tensor is: tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64)\n",
            " the A tensor value is: tensor([[0.8694, 0.5677, 0.7411, 0.4294],\n",
            "        [0.8854, 0.5739, 0.2666, 0.6274],\n",
            "        [0.2696, 0.4414, 0.2969, 0.8317]])\n",
            " the B tensor value is: tensor([[0.1053, 0.2695, 0.3588, 0.1994],\n",
            "        [0.5472, 0.0062, 0.9516, 0.0753],\n",
            "        [0.8860, 0.5832, 0.3376, 0.8090]])\n",
            " the C tensor value is: tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
            "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
            "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
            " the D tensor value is: tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
            "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
            "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
            "tensor([[True, True, True, True],\n",
            "        [True, True, True, True],\n",
            "        [True, True, True, True]])\n"
          ]
        }
      ]
    }
  ]
}